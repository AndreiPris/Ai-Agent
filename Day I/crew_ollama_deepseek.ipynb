{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AndreiPris/Ai-Agent/blob/main/Day%20I/crew_ollama_deepseek.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f5c5bbdd"
      },
      "source": [
        "# üß† AI Agents Bootcamp: Running DeepSeek with CrewAI and Ollama\n",
        "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/vipbasil/aibootcamp/blob/main/Day%20I/crew_ollama_deepseek.ipynb?raw=true)\n",
        "\n",
        "This notebook is part of the AI Agents Bootcamp (23‚Äì27 June 2025) ‚Äî it shows how to:\n",
        "- Set up the `Ollama` environment in Colab\n",
        "- Run `DeepSeek` models locally for use in CrewAI/MAS pipelines\n",
        "- Prepare agents that use locally-hosted LLMs with memory and tools"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "19eeeee4"
      },
      "source": [
        "## ‚öôÔ∏è Step 1: Environment Setup\n",
        "This installs and runs the `ollama` backend and exposes the service via localtunnel tunnel. Make sure to:\n",
        "- Restart the runtime if needed\n",
        "- Use the ngrok alternative (if Cloudflare is blocked or throttled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ssm5RJKID82Z"
      },
      "outputs": [],
      "source": [
        "%pip install ollama\n",
        "%pip install colab-xterm"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RimdapHHa7b9"
      },
      "source": [
        "## üõ†Ô∏è System Info Tools (Optional)\n",
        "\n",
        "Installs utilities (`pciutils`, `lshw`) to inspect hardware specs ‚Äî useful for checking GPU/CPU availability in Colab or local runtime.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eBW3P8YuECqz"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get update\n",
        "!sudo apt-get install pciutils lshw"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CsSHIndzbDOB"
      },
      "source": [
        "## üì¶ Ollama Installation\n",
        "\n",
        "Downloads and installs Ollama via the official shell script ‚Äî run this once per environment setup."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AwFE191pEGaI"
      },
      "outputs": [],
      "source": [
        "!curl -fsSL https://ollama.com/install.sh | sh"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5285c8c4"
      },
      "source": [
        "## üîß Step 2: Programmatic Model Management and Server Initialization\n",
        "\n",
        "In this section, we:\n",
        "- Import the required libraries for managing subprocesses, HTTP requests, and multithreading\n",
        "- Start the Ollama server programmatically using a background thread\n",
        "- Pull the required models (`deepseek-r1:7b`, `llama3`) using `ollama pull`\n",
        "- Optionally include fallback to a smaller model (`deepseek-r1:1.5b`)\n",
        "- Confirm the list of available models and test that the local Ollama server is running at `localhost:11434`\n",
        "\n",
        "üìå **Why it matters**: This sets up your local model infrastructure for agent interaction. You'll later reference `localhost:11434` in your agent definitions to connect to these models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cqoaeOpaEZZ8"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "import subprocess\n",
        "import requests\n",
        "import json\n",
        "import threading\n",
        "from pprint import pprint"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRLABB5HZZo7"
      },
      "source": [
        "##  Launching the Ollama Server in Background\n",
        "\n",
        "Before using any model, we need to start the **Ollama inference server**, which listens by default on `localhost:11434`.\n",
        "\n",
        "This snippet:\n",
        "- Defines a Python function `run_ollama()` that launches `ollama serve`\n",
        "- Starts it in a **background thread**, so the notebook remains interactive\n",
        "- Allows the server to stay active without blocking further cells\n",
        "\n",
        "üõ†Ô∏è **Note**: You only need to run this once per session. If you restart your Colab, re-run this cell before using any models.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f370227"
      },
      "outputs": [],
      "source": [
        "# Start the Ollama server\n",
        "def run_ollama():\n",
        "  subprocess.Popen([\"ollama\", \"serve\"])\n",
        "thread = threading.Thread(target=run_ollama)\n",
        "thread.start()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QSnmd7ryZqNM"
      },
      "source": [
        "## üì• Pulling Models\n",
        "\n",
        "We download pre-trained models from the Ollama registry:\n",
        "- `deepseek-r1:7b` ‚Äì reasoning & code\n",
        "- `llama3` ‚Äì general-purpose assistant"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6723baed"
      },
      "outputs": [],
      "source": [
        "# Download the deepseek-r1:7b distilled model\n",
        "!ollama pull deepseek-r1:7b\n",
        "!ollama pull llama3\n",
        "# If this doesn't work, you can uncomment the below code to download a smaller model- deepseek-r1:1.5b\n",
        "# !ollama pull deepseek-r1:1.5b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0eZ8XjjMZ3ip"
      },
      "source": [
        "## ü™∂ Pulling Lightweight SLMs\n",
        "\n",
        "These small models are ideal for fast local agents and low-resource environments:\n",
        "- `phi3:mini`, `tinyllama` ‚Äì ultra-small general models\n",
        "- `gemma:2b` ‚Äì Google's compact chat model\n",
        "- `deepseek-r1:1.5b` ‚Äì distilled reasoning model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbNtHtlRHlWG"
      },
      "outputs": [],
      "source": [
        "!ollama pull phi3:mini\n",
        "!ollama pull tinyllama\n",
        "!ollama pull gemma:2b\n",
        "!ollama pull deepseek-r1:1.5b"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SLHS7WUwaMNk"
      },
      "source": [
        "## üîå Test Ollama Server\n",
        "\n",
        "Sends a test request to verify the Ollama server is running on `localhost:11434`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7aae1987"
      },
      "outputs": [],
      "source": [
        "!curl http://127.0.0.1:11434"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V5JaeB4YaAlx"
      },
      "source": [
        "## üìÑ Check Installed Models\n",
        "\n",
        "Lists all models currently downloaded and available in your local Ollama environment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9809d934"
      },
      "outputs": [],
      "source": [
        "!ollama list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "504891b1"
      },
      "source": [
        "# üß† Starting the CrewAI Section\n",
        "\n",
        "##Now we define agents using CrewAI, connected to our locally running Ollama models.  \n",
        "##This enables multi-agent workflows powered by lightweight, self-hosted LLMs.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f26b8d0b"
      },
      "outputs": [],
      "source": [
        "# @title üë®‚Äçü¶Ø Run this cell to hide all warnings (optional)\n",
        "# Warning control\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# To avoid the restart session warning in Colab, exclude the PIL and\n",
        "# pydevd_plugins packages from being imported. This is fine because\n",
        "# we didn't execute the code in the kernel session afterward.\n",
        "\n",
        "# import sys\n",
        "# sys.modules.pop('PIL', None)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ca86609"
      },
      "outputs": [],
      "source": [
        "# @title ‚¨áÔ∏è Install project dependencies by running this cell\n",
        "%pip install git+https://github.com/joaomdmoura/crewAI.git --quiet\n",
        "%pip install crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere --quiet\n",
        "print(\"---\")\n",
        "%pip show crewAI crewai_tools langchain_openai langchain_groq langchain_anthropic langchain_community cohere"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4f36bef0"
      },
      "outputs": [],
      "source": [
        "%pip install -qU langchain-ollama"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "577d53c4"
      },
      "source": [
        "## üß© Step 3: CrewAI Integration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "88866d05"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from textwrap import dedent\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eb30a521"
      },
      "source": [
        "## Define Agents\n",
        "In CrewAI, agents are autonomous entities designed to perform specific roles and achieve particular goals. Each agent uses a language model (LLM) and may have specialized tools to help execute tasks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c416f4fe",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üïµüèª Define your agents\n",
        "# import os\n",
        "# import json\n",
        "# from datetime import datetime, timedelta\n",
        "# # from crewai import Agent, Task, Crew, Process, LLM\n",
        "# # from textwrap import dedent\n",
        "# import warnings\n",
        "# warnings.filterwarnings('ignore')\n",
        "\n",
        "from crewai import Agent\n",
        "from textwrap import dedent\n",
        "from langchain_ollama import ChatOllama\n",
        "# Define LLM (OpenAI used here; replace as needed)\n",
        "from crewai import LLM\n",
        "\n",
        "llm = LLM(model=\"ollama/tinyllama:latest\", base_url=\"http://127.0.0.1:11434\")\n",
        "\n",
        "# =============================================================================\n",
        "# –ê–ì–ï–ù–¢ 1: –ö–û–ù–°–£–õ–¨–¢–ê–ù–¢ –ü–û –ö–õ–ò–ï–ù–¢–ê–ú\n",
        "# =============================================================================\n",
        "\n",
        "customer_consultant = Agent(\n",
        "    role=dedent(\"\"\"Customer Service Consultant\"\"\"),\n",
        "    goal=dedent(\"\"\"Provide respectful, concise, and effective customer consultations for lingerie purchases\"\"\"),\n",
        "    backstory=dedent(\"\"\"\n",
        "        –í—ã ‚Äî –ø—Ä–æ—Ñ–µ—Å—Å–∏–æ–Ω–∞–ª—å–Ω—ã–π –∫–æ–Ω—Å—É–ª—å—Ç–∞–Ω—Ç –ø—Ä–µ–º–∏—É–º-–±—Ä–µ–Ω–¥–∞ –Ω–∏–∂–Ω–µ–≥–æ –±–µ–ª—å—è —Å 10+ –ª–µ—Ç –æ–ø—ã—Ç–∞.\n",
        "        –í–∞—à —Å—Ç–∏–ª—å –æ–±—â–µ–Ω–∏—è: —É–≤–∞–∂–∏—Ç–µ–ª—å–Ω—ã–π, –ª–∞–∫–æ–Ω–∏—á–Ω—ã–π, –ø–æ —Å—É—â–µ—Å—Ç–≤—É. –í—ã –±—ã—Å—Ç—Ä–æ –ø–æ–Ω–∏–º–∞–µ—Ç–µ\n",
        "        –ø–æ—Ç—Ä–µ–±–Ω–æ—Å—Ç–∏ –∫–ª–∏–µ–Ω—Ç–∞ –∏ –¥–∞–µ—Ç–µ —á–µ—Ç–∫–∏–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –±–µ–∑ –ª–∏—à–Ω–∏—Ö —Å–ª–æ–≤.\n",
        "        –ú–∞–∫—Å–∏–º—É–º 3-4 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –≤ –æ—Ç–≤–µ—Ç–µ. –¶–µ–Ω–∏—Ç–µ –≤—Ä–µ–º—è –∫–ª–∏–µ–Ω—Ç–∞.\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# –ê–ì–ï–ù–¢ 2: –õ–û–ì–ò–°–¢\n",
        "# =============================================================================\n",
        "\n",
        "logistics_specialist = Agent(\n",
        "    role=dedent(\"\"\"Delivery Logistics Coordinator\"\"\"),\n",
        "    goal=dedent(\"\"\"Calculate optimal delivery routes and provide accurate delivery times\"\"\"),\n",
        "    backstory=dedent(\"\"\"\n",
        "        –í—ã ‚Äî –æ–ø—ã—Ç–Ω—ã–π –ª–æ–≥–∏—Å—Ç —Å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–æ–π –≤ –æ–±–ª–∞—Å—Ç–∏ –¥–æ—Å—Ç–∞–≤–∫–∏ —Ç–æ–≤–∞—Ä–æ–≤ –ø–æ –ö–∏—à–∏–Ω–µ–≤—É.\n",
        "        –ó–Ω–∞–µ—Ç–µ –≤—Å–µ —Ä–∞–π–æ–Ω—ã –≥–æ—Ä–æ–¥–∞, —É—á–∏—Ç—ã–≤–∞–µ—Ç–µ –ø—Ä–æ–±–∫–∏, –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–µ –º–∞—Ä—à—Ä—É—Ç—ã.\n",
        "        –£–º–µ–µ—Ç–µ —Ç–æ—á–Ω–æ —Ä–∞—Å—Å—á–∏—Ç—ã–≤–∞—Ç—å –≤—Ä–µ–º—è –¥–æ—Å—Ç–∞–≤–∫–∏ —Å —É—á–µ—Ç–æ–º —Ç–µ–∫—É—â–µ–π –¥–æ—Ä–æ–∂–Ω–æ–π —Å–∏—Ç—É–∞—Ü–∏–∏,\n",
        "        —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –∏ –∑–∞–≥—Ä—É–∂–µ–Ω–Ω–æ—Å—Ç–∏ –∫—É—Ä—å–µ—Ä–æ–≤.\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# –ê–ì–ï–ù–¢ 3: –ö–õ–ê–î–û–í–©–ò–ö\n",
        "# =============================================================================\n",
        "\n",
        "warehouse_manager = Agent(\n",
        "    role=dedent(\"\"\"Inventory Database Manager\"\"\"),\n",
        "    goal=dedent(\"\"\"Track and manage product inventory across all store locations\"\"\"),\n",
        "    backstory=dedent(\"\"\"\n",
        "        –í—ã ‚Äî —Ç–æ—á–Ω—ã–π –∏ –æ—Ä–≥–∞–Ω–∏–∑–æ–≤–∞–Ω–Ω—ã–π –∫–ª–∞–¥–æ–≤—â–∏–∫, –∫–æ—Ç–æ—Ä—ã–π –≤–µ–¥–µ—Ç –±–∞–∑—É –¥–∞–Ω–Ω—ã—Ö –≤—Å–µ—Ö —Ç–æ–≤–∞—Ä–æ–≤:\n",
        "        –º–æ–¥–µ–ª–∏, —Ü–≤–µ—Ç–∞, —Ä–∞–∑–º–µ—Ä—ã, –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –Ω–∞ —Å–∫–ª–∞–¥–∞—Ö —Ä–∞–∑–Ω—ã—Ö –º–∞–≥–∞–∑–∏–Ω–æ–≤.\n",
        "        –ú–≥–Ω–æ–≤–µ–Ω–Ω–æ –Ω–∞—Ö–æ–¥–∏—Ç–µ –Ω—É–∂–Ω—ã–π —Ç–æ–≤–∞—Ä, –æ—Ç—Å–ª–µ–∂–∏–≤–∞–µ—Ç–µ –æ—Å—Ç–∞—Ç–∫–∏ –∏ —Ç–æ—á–Ω–æ –∑–Ω–∞–µ—Ç–µ,\n",
        "        –≥–¥–µ –∫–∞–∫–æ–π —Ç–æ–≤–∞—Ä –Ω–∞—Ö–æ–¥–∏—Ç—Å—è –∏ –≤ –∫–∞–∫–æ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–µ.\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# –ê–ì–ï–ù–¢ 4: –ú–ê–†–ö–ï–¢–û–õ–û–ì\n",
        "# =============================================================================\n",
        "\n",
        "marketing_specialist = Agent(\n",
        "    role=dedent(\"\"\"Marketing Campaign Creator\"\"\"),\n",
        "    goal=dedent(\"\"\"Create compelling promotional materials and customer engagement campaigns\"\"\"),\n",
        "    backstory=dedent(\"\"\"\n",
        "        –í—ã ‚Äî –∫—Ä–µ–∞—Ç–∏–≤–Ω—ã–π –º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ –Ω–∏–∂–Ω–µ–≥–æ –±–µ–ª—å—è.\n",
        "        –£–º–µ–µ—Ç–µ —Å–æ–∑–¥–∞–≤–∞—Ç—å –ø—Ä–∏–≤–ª–µ–∫–∞—Ç–µ–ª—å–Ω—ã–µ –∞–∫—Ü–∏–∏, –ø–∏—Å–∞—Ç—å —Ü–µ–ø–ª—è—é—â–∏–µ —Ç–µ–∫—Å—Ç—ã –¥–ª—è email-—Ä–∞—Å—Å—ã–ª–æ–∫,\n",
        "        —Å–æ—Ü–∏–∞–ª—å–Ω—ã—Ö —Å–µ—Ç–µ–π –∏ —Ä–µ–∫–ª–∞–º—ã. –ó–Ω–∞–µ—Ç–µ –ø—Å–∏—Ö–æ–ª–æ–≥–∏—é –ø–æ–∫—É–ø–∞—Ç–µ–ª–µ–π –∏ —É–º–µ–µ—Ç–µ –º–æ—Ç–∏–≤–∏—Ä–æ–≤–∞—Ç—å –Ω–∞ –ø–æ–∫—É–ø–∫—É.\n",
        "        –°–æ–∑–¥–∞–µ—Ç–µ –∫–æ–Ω—Ç–µ–Ω—Ç, –∫–æ—Ç–æ—Ä—ã–π —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç –ø—Ä–æ–¥–∞–∂–∏.\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=3,\n",
        "    llm=llm\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ef6272d6"
      },
      "source": [
        "## Define Tasks\n",
        "Tasks in CrewAI are specific assignments given to agents, detailing the actions they need to perform to achieve a particular goal. Tasks can have dependencies and context, and can be executed asynchronously to ensure an efficient workflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8249b567",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üìù Define your tasks\n",
        "from crewai import Task\n",
        "from textwrap import dedent\n",
        "\n",
        "# Task 1: Researcher\n",
        "task_1 = Task(\n",
        "    description=dedent(\"\"\"\n",
        "        Research recent developments in open-source large language models (LLMs), with a focus on DeepSeek, its capabilities, and recent benchmarks. Identify 2‚Äì3 major advantages compared to closed-source models.\n",
        "    \"\"\"),\n",
        "    expected_output=dedent(\"\"\"\n",
        "        A structured summary (~200 words) covering:\n",
        "        - What DeepSeek is and who developed it\n",
        "        - Key features or innovations\n",
        "        - At least two comparative strengths of open-source LLMs\n",
        "    \"\"\"),\n",
        "    agent=agent_1,\n",
        ")\n",
        "\n",
        "# Task 2: Analyst\n",
        "task_2 = Task(\n",
        "    description=dedent(\"\"\"\n",
        "        Analyze the research findings about DeepSeek and extract educational implications. Focus on how this technology could benefit educators, students, or institutions using local infrastructure.\n",
        "    \"\"\"),\n",
        "    expected_output=dedent(\"\"\"\n",
        "        A short analytical breakdown (~150 words) including:\n",
        "        - 2‚Äì3 practical use cases in education\n",
        "        - The impact of offline/local LLMs on cost and data privacy\n",
        "        - Any challenges or limitations to note\n",
        "    \"\"\"),\n",
        "    agent=agent_2,\n",
        "    context=[task_1],\n",
        ")\n",
        "\n",
        "# Task 3: Writer\n",
        "task_3 = Task(\n",
        "    description=dedent(\"\"\"\n",
        "        Write a clear, engaging blog post summarizing the findings and analysis into a cohesive article titled:\n",
        "        \"How Open-Source AI Like DeepSeek Is Changing Education.\"\n",
        "    \"\"\"),\n",
        "    expected_output=dedent(\"\"\"\n",
        "        A 400‚Äì500 word markdown-formatted blog post including:\n",
        "        - Title and subtitle\n",
        "        - Introduction\n",
        "        - Three core paragraphs with bullet points if needed\n",
        "        - Conclusion and future outlook\n",
        "    \"\"\"),\n",
        "    agent=agent_3,\n",
        "    context=[task_2],\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0bb55322"
      },
      "outputs": [],
      "source": [
        "print(\"## üë• Welcome to the DeepSeek Research Crew\")\n",
        "print('-------------------------------------------')\n",
        "\n",
        "# Input variables for tasks\n",
        "var_1 = input(\"üîç Topic or model to explore (e.g., DeepSeek)?\\n\")\n",
        "var_2 = input(\"üéØ Who is the target audience (e.g., educators, developers)?\\n\")\n",
        "var_3 = input(\"üß† What‚Äôs the intended output format (e.g., article, summary)?\\n\")\n",
        "\n",
        "print('-------------------------------------------')\n",
        "print(f\"‚úîÔ∏è Input received:\\nModel: {var_1}\\nAudience: {var_2}\\nOutput Type: {var_3}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1c658581",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üöÄ Get your crew to work!\n",
        "def main():\n",
        "    # Instantiate your crew with a sequential process\n",
        "    crew = Crew(\n",
        "        agents=[agent_1, agent_2, agent_3],\n",
        "        tasks=[task_1, task_2, task_3],\n",
        "        verbose=True,  # You can set it to True or False\n",
        "        # ‚Üë indicates the verbosity level for logging during execution.\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "        # ‚Üë the process flow that the crew will follow (e.g., sequential, hierarchical).\n",
        "    )\n",
        "\n",
        "    inputs = {\n",
        "    \"var_1\": var_1,\n",
        "    \"var_2\": var_2,\n",
        "    \"var_3\": var_3\n",
        "    }\n",
        "\n",
        "    result = crew.kickoff(inputs=inputs)\n",
        "    print(\"\\n\\n########################\")\n",
        "    print(\"## Here is your custom crew run result:\")\n",
        "    print(\"########################\\n\")\n",
        "    print(result)\n",
        "\n",
        "    return result\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  result = main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "889206a0",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title üñ•Ô∏è Display the results of your crew as markdown\n",
        "from IPython.display import display, Markdown\n",
        "\n",
        "markdown_text = result.raw  # Adjust this based on the actual attribute\n",
        "\n",
        "# Display the markdown content\n",
        "display(Markdown(markdown_text))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ü©± AI Agents for Lingerie Brand - Google Colab Version (English)\n",
        "# Adapted for bootcamp environment with phi3:mini model\n",
        "\n",
        "import os\n",
        "import json\n",
        "from datetime import datetime, timedelta\n",
        "from crewai import Agent, Task, Crew, Process, LLM\n",
        "from textwrap import dedent\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# =============================================================================\n",
        "# LLM SETUP FOR ALL AGENTS\n",
        "# =============================================================================\n",
        "\n",
        "# Using phi3:mini model for better performance\n",
        "llm = LLM(model=\"ollama/phi3:mini\", base_url=\"http://127.0.0.1:11434\")\n",
        "\n",
        "# –ê–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω–æ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –¥—Ä—É–≥–∏–µ –º–æ–¥–µ–ª–∏:\n",
        "# llm = LLM(model=\"ollama/tinyllama:latest\", base_url=\"http://127.0.0.1:11434\")\n",
        "# llm = LLM(model=\"ollama/phi3:mini\", base_url=\"http://127.0.0.1:11434\")\n",
        "# llm = LLM(model=\"ollama/deepseek-r1:1.5b\", base_url=\"http://127.0.0.1:11434\")\n",
        "\n",
        "print(\"ü§ñ Initializing AI Agents for Lingerie Brand...\")\n",
        "print(\"üîó Connecting to Ollama:\", \"http://127.0.0.1:11434\")\n",
        "print(\"üß† Using model: phi3:mini\")\n",
        "\n",
        "# =============================================================================\n",
        "# AGENT 1: CUSTOMER CONSULTANT\n",
        "# =============================================================================\n",
        "\n",
        "customer_consultant = Agent(\n",
        "    role=\"Customer Service Consultant\",\n",
        "    goal=\"Provide respectful, concise, and effective customer consultations for lingerie purchases\",\n",
        "    backstory=dedent(\"\"\"\n",
        "        You are a professional consultant for a premium lingerie brand with 10+ years of experience.\n",
        "        Your communication style is: respectful, concise, and to the point. You quickly understand\n",
        "        customer needs and provide clear recommendations without unnecessary words.\n",
        "        Maximum 3-4 sentences in your response. You value the customer's time.\n",
        "\n",
        "        You know:\n",
        "        - Bra sizing basics: band size + cup size\n",
        "        - Common fitting issues and solutions\n",
        "        - Different bra styles and their purposes\n",
        "        - When to ask clarifying questions\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=2,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# AGENT 2: LOGISTICS SPECIALIST\n",
        "# =============================================================================\n",
        "\n",
        "logistics_specialist = Agent(\n",
        "    role=\"Delivery Logistics Coordinator\",\n",
        "    goal=\"Calculate optimal delivery routes and provide accurate delivery times\",\n",
        "    backstory=dedent(\"\"\"\n",
        "        You are an experienced logistics coordinator with expertise in delivery services in Chisinau.\n",
        "        You know all city districts, account for traffic jams, and optimal routes.\n",
        "        You can accurately calculate delivery times considering current traffic situation,\n",
        "        distance, and courier availability.\n",
        "\n",
        "        You understand:\n",
        "        - Different delivery zones and their characteristics\n",
        "        - Traffic patterns throughout the day\n",
        "        - Courier capacity and vehicle types\n",
        "        - Cost calculation based on distance and zone\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=2,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# AGENT 3: WAREHOUSE MANAGER\n",
        "# =============================================================================\n",
        "\n",
        "warehouse_manager = Agent(\n",
        "    role=\"Inventory Database Manager\",\n",
        "    goal=\"Track and manage product inventory across all store locations\",\n",
        "    backstory=dedent(\"\"\"\n",
        "        You are a precise and organized warehouse manager who maintains a database of all products:\n",
        "        models, colors, sizes, quantities at different store warehouses.\n",
        "        You can instantly find the right product, track inventory levels, and know exactly\n",
        "        where each item is located and in what quantity.\n",
        "\n",
        "        You manage:\n",
        "        - Product catalog with all variants\n",
        "        - Inventory levels across multiple stores\n",
        "        - Stock reservations and availability\n",
        "        - Store locations and addresses\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=2,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# AGENT 4: MARKETING SPECIALIST\n",
        "# =============================================================================\n",
        "\n",
        "marketing_specialist = Agent(\n",
        "    role=\"Marketing Campaign Creator\",\n",
        "    goal=\"Create compelling promotional materials and customer engagement campaigns\",\n",
        "    backstory=dedent(\"\"\"\n",
        "        You are a creative marketer specializing in the lingerie industry.\n",
        "        You can create attractive promotions, write engaging texts for email campaigns,\n",
        "        social media, and advertising. You understand customer psychology and know how to motivate purchases.\n",
        "        You create content that increases sales.\n",
        "\n",
        "        Your expertise includes:\n",
        "        - Understanding lingerie market psychology\n",
        "        - Creating tasteful and appealing campaigns\n",
        "        - Email marketing and social media content\n",
        "        - Seasonal trends and promotional strategies\n",
        "    \"\"\"),\n",
        "    allow_delegation=False,\n",
        "    verbose=True,\n",
        "    max_iter=2,\n",
        "    llm=llm\n",
        ")\n",
        "\n",
        "# =============================================================================\n",
        "# MOCK DATABASE - SIMPLIFIED DATABASE FOR COLAB\n",
        "# =============================================================================\n",
        "\n",
        "# Since Colab doesn't have SQLite, we use dictionaries\n",
        "PRODUCTS_DB = {\n",
        "    \"1\": {\"model\": \"Comfort Plus\", \"brand\": \"Intimissimi\", \"color\": \"Black\", \"size\": \"75B\", \"price\": 89.90},\n",
        "    \"2\": {\"model\": \"Comfort Plus\", \"brand\": \"Intimissimi\", \"color\": \"Beige\", \"size\": \"75B\", \"price\": 89.90},\n",
        "    \"3\": {\"model\": \"Comfort Plus\", \"brand\": \"Intimissimi\", \"color\": \"Black\", \"size\": \"75C\", \"price\": 89.90},\n",
        "    \"4\": {\"model\": \"Elegant\", \"brand\": \"Victoria Secret\", \"color\": \"Red\", \"size\": \"75B\", \"price\": 159.90},\n",
        "    \"5\": {\"model\": \"Sport Active\", \"brand\": \"Nike\", \"color\": \"Gray\", \"size\": \"M\", \"price\": 79.90},\n",
        "    \"6\": {\"model\": \"Bridal\", \"brand\": \"La Perla\", \"color\": \"White\", \"size\": \"70B\", \"price\": 299.90},\n",
        "}\n",
        "\n",
        "INVENTORY_DB = {\n",
        "    \"1\": {\"product_id\": \"1\", \"store\": \"Central Store\", \"quantity\": 15, \"address\": \"Stefan cel Mare 126 St, Chisinau\"},\n",
        "    \"2\": {\"product_id\": \"1\", \"store\": \"Mall Shopping\", \"quantity\": 8, \"address\": \"Malldova TC, Chisinau\"},\n",
        "    \"3\": {\"product_id\": \"2\", \"store\": \"Central Store\", \"quantity\": 12, \"address\": \"Stefan cel Mare 126 St, Chisinau\"},\n",
        "    \"4\": {\"product_id\": \"5\", \"store\": \"Central Store\", \"quantity\": 25, \"address\": \"Stefan cel Mare 126 St, Chisinau\"},\n",
        "    \"5\": {\"product_id\": \"6\", \"store\": \"Botanica Boutique\", \"quantity\": 3, \"address\": \"Dacia 47 St, Chisinau\"},\n",
        "}\n",
        "\n",
        "DELIVERY_ZONES = {\n",
        "    \"Center\": {\"time\": 20, \"cost\": 25.0, \"traffic_multiplier\": 1.2},\n",
        "    \"Botanica\": {\"time\": 35, \"cost\": 30.0, \"traffic_multiplier\": 1.1},\n",
        "    \"Riscani\": {\"time\": 45, \"cost\": 35.0, \"traffic_multiplier\": 1.3},\n",
        "    \"Buiucani\": {\"time\": 40, \"cost\": 35.0, \"traffic_multiplier\": 1.2},\n",
        "}\n",
        "\n",
        "# =============================================================================\n",
        "# TASKS FOR EACH AGENT\n",
        "# =============================================================================\n",
        "\n",
        "def create_consultation_task(customer_query):\n",
        "    \"\"\"Creates customer consultation task\"\"\"\n",
        "    return Task(\n",
        "        description=dedent(f\"\"\"\n",
        "            A customer asked: \"{customer_query}\"\n",
        "\n",
        "            Response requirements:\n",
        "            - Maximum 3-4 sentences\n",
        "            - Respectful tone\n",
        "            - Specific recommendations\n",
        "            - No unnecessary words\n",
        "            - If additional information is needed - ask 1 clarifying question\n",
        "\n",
        "            Remember you are a professional lingerie consultant helping customers find the right fit and style.\n",
        "        \"\"\"),\n",
        "        expected_output=dedent(\"\"\"\n",
        "            Brief professional response including:\n",
        "            - Greeting (if first contact)\n",
        "            - Specific recommendation or solution\n",
        "            - Clarifying question (if needed)\n",
        "            - Polite closing\n",
        "        \"\"\"),\n",
        "        agent=customer_consultant\n",
        "    )\n",
        "\n",
        "def create_inventory_task(product_request):\n",
        "    \"\"\"Creates inventory check task\"\"\"\n",
        "\n",
        "    # Search in mock database\n",
        "    found_products = []\n",
        "    for pid, product in PRODUCTS_DB.items():\n",
        "        if any(word.lower() in product[\"model\"].lower() or\n",
        "               word.lower() in product[\"color\"].lower() or\n",
        "               word.lower() in product[\"size\"].lower()\n",
        "               for word in product_request.split()):\n",
        "            # Search in inventory\n",
        "            for iid, inventory in INVENTORY_DB.items():\n",
        "                if inventory[\"product_id\"] == pid:\n",
        "                    found_products.append({\n",
        "                        \"model\": product[\"model\"],\n",
        "                        \"color\": product[\"color\"],\n",
        "                        \"size\": product[\"size\"],\n",
        "                        \"price\": product[\"price\"],\n",
        "                        \"store\": inventory[\"store\"],\n",
        "                        \"quantity\": inventory[\"quantity\"],\n",
        "                        \"address\": inventory[\"address\"]\n",
        "                    })\n",
        "\n",
        "    inventory_data = json.dumps(found_products, ensure_ascii=False, indent=2)\n",
        "\n",
        "    return Task(\n",
        "        description=dedent(f\"\"\"\n",
        "            Check product availability for request: \"{product_request}\"\n",
        "\n",
        "            Database results:\n",
        "            {inventory_data}\n",
        "\n",
        "            Provide information about:\n",
        "            - Availability by stores\n",
        "            - Exact quantities\n",
        "            - Store addresses\n",
        "            - Prices\n",
        "            - Reservation possibility\n",
        "        \"\"\"),\n",
        "        expected_output=dedent(\"\"\"\n",
        "            Complete product availability information:\n",
        "            - List of found products\n",
        "            - Store availability with addresses\n",
        "            - Quantities in stock\n",
        "            - Prices\n",
        "            - Store selection recommendations\n",
        "        \"\"\"),\n",
        "        agent=warehouse_manager\n",
        "    )\n",
        "\n",
        "def create_logistics_task(delivery_request):\n",
        "    \"\"\"Creates delivery planning task\"\"\"\n",
        "\n",
        "    # Determine delivery zone\n",
        "    zone = \"Center\"  # default\n",
        "    if \"botanica\" in delivery_request.lower() or \"dacia\" in delivery_request.lower():\n",
        "        zone = \"Botanica\"\n",
        "    elif \"riscani\" in delivery_request.lower():\n",
        "        zone = \"Riscani\"\n",
        "    elif \"buiucani\" in delivery_request.lower():\n",
        "        zone = \"Buiucani\"\n",
        "\n",
        "    zone_info = DELIVERY_ZONES.get(zone, DELIVERY_ZONES[\"Center\"])\n",
        "    current_time = datetime.now()\n",
        "\n",
        "    # Calculate time considering traffic\n",
        "    hour = current_time.hour\n",
        "    multiplier = zone_info[\"traffic_multiplier\"]\n",
        "    if 8 <= hour <= 10 or 17 <= hour <= 19:  # rush hour\n",
        "        multiplier *= 1.5\n",
        "\n",
        "    delivery_time = int(zone_info[\"time\"] * multiplier)\n",
        "    arrival_time = current_time + timedelta(minutes=delivery_time)\n",
        "\n",
        "    logistics_data = {\n",
        "        \"zone\": zone,\n",
        "        \"base_time\": zone_info[\"time\"],\n",
        "        \"traffic_multiplier\": multiplier,\n",
        "        \"delivery_time\": delivery_time,\n",
        "        \"arrival_time\": arrival_time.strftime('%H:%M'),\n",
        "        \"cost\": zone_info[\"cost\"],\n",
        "        \"current_time\": current_time.strftime('%H:%M')\n",
        "    }\n",
        "\n",
        "    return Task(\n",
        "        description=dedent(f\"\"\"\n",
        "            Calculate delivery for order: \"{delivery_request}\"\n",
        "\n",
        "            Calculated data:\n",
        "            {json.dumps(logistics_data, ensure_ascii=False, indent=2)}\n",
        "\n",
        "            Consider:\n",
        "            - Current time and traffic\n",
        "            - Distance to delivery zone\n",
        "            - Road congestion\n",
        "            - Order priority\n",
        "        \"\"\"),\n",
        "        expected_output=dedent(\"\"\"\n",
        "            Complete delivery plan including:\n",
        "            - Delivery zone\n",
        "            - Exact arrival time\n",
        "            - Delivery cost\n",
        "            - Traffic and road situation considerations\n",
        "            - Order timing recommendations\n",
        "        \"\"\"),\n",
        "        agent=logistics_specialist\n",
        "    )\n",
        "\n",
        "def create_marketing_task(campaign_brief):\n",
        "    \"\"\"Creates marketing campaign task\"\"\"\n",
        "    return Task(\n",
        "        description=dedent(f\"\"\"\n",
        "            Create marketing campaign: \"{campaign_brief}\"\n",
        "\n",
        "            Develop:\n",
        "            - Attractive offer\n",
        "            - Catchy headline\n",
        "            - Text for different channels (email, social media)\n",
        "            - Campaign conditions\n",
        "            - Call-to-action\n",
        "\n",
        "            Consider lingerie sales specifics:\n",
        "            - Topic sensitivity\n",
        "            - Customer psychology\n",
        "            - Seasonality and trends\n",
        "        \"\"\"),\n",
        "        expected_output=dedent(\"\"\"\n",
        "            Ready marketing campaign including:\n",
        "            - Campaign headline\n",
        "            - Main offer text\n",
        "            - Participation conditions\n",
        "            - Call to action\n",
        "            - Adaptation for email and Instagram\n",
        "        \"\"\"),\n",
        "        agent=marketing_specialist\n",
        "    )\n",
        "\n",
        "# =============================================================================\n",
        "# READY SCENARIOS FOR TESTING\n",
        "# =============================================================================\n",
        "\n",
        "def scenario_customer_consultation(query):\n",
        "    \"\"\"Scenario 1: Customer consultation\"\"\"\n",
        "    print(f\"\\nüìû CUSTOMER CONSULTATION:\")\n",
        "    print(f\"Query: {query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    task = create_consultation_task(query)\n",
        "    crew = Crew(\n",
        "        agents=[customer_consultant],\n",
        "        tasks=[task],\n",
        "        verbose=False,\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(f\"ü§ñ Consultant's response:\\n{result}\")\n",
        "    return result\n",
        "\n",
        "def scenario_inventory_check(product_query):\n",
        "    \"\"\"Scenario 2: Inventory check\"\"\"\n",
        "    print(f\"\\nüì¶ INVENTORY CHECK:\")\n",
        "    print(f\"Search: {product_query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    task = create_inventory_task(product_query)\n",
        "    crew = Crew(\n",
        "        agents=[warehouse_manager],\n",
        "        tasks=[task],\n",
        "        verbose=False,\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(f\"ü§ñ Warehouse manager's report:\\n{result}\")\n",
        "    return result\n",
        "\n",
        "def scenario_delivery_planning(delivery_query):\n",
        "    \"\"\"Scenario 3: Delivery planning\"\"\"\n",
        "    print(f\"\\nüöö DELIVERY PLANNING:\")\n",
        "    print(f\"Address: {delivery_query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    task = create_logistics_task(delivery_query)\n",
        "    crew = Crew(\n",
        "        agents=[logistics_specialist],\n",
        "        tasks=[task],\n",
        "        verbose=False,\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(f\"ü§ñ Delivery plan:\\n{result}\")\n",
        "    return result\n",
        "\n",
        "def scenario_marketing_campaign(campaign_query):\n",
        "    \"\"\"Scenario 4: Marketing campaign\"\"\"\n",
        "    print(f\"\\nüì¢ MARKETING CAMPAIGN:\")\n",
        "    print(f\"Brief: {campaign_query}\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    task = create_marketing_task(campaign_query)\n",
        "    crew = Crew(\n",
        "        agents=[marketing_specialist],\n",
        "        tasks=[task],\n",
        "        verbose=False,\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(f\"ü§ñ Marketing campaign:\\n{result}\")\n",
        "    return result\n",
        "\n",
        "def scenario_complex_order():\n",
        "    \"\"\"Scenario 5: Complex order processing\"\"\"\n",
        "    print(f\"\\nüõçÔ∏è COMPLEX ORDER PROCESSING\")\n",
        "    print(\"-\" * 50)\n",
        "\n",
        "    customer_query = \"Looking for a comfortable sports bra in gray color, size 75B, with delivery to Botanica district\"\n",
        "\n",
        "    # Create tasks for all agents\n",
        "    consultation_task = create_consultation_task(customer_query)\n",
        "    inventory_task = create_inventory_task(\"sports gray 75B\")\n",
        "    delivery_task = create_logistics_task(\"delivery to Botanica, Dacia 47 street\")\n",
        "\n",
        "    # Create team of all agents\n",
        "    crew = Crew(\n",
        "        agents=[customer_consultant, warehouse_manager, logistics_specialist],\n",
        "        tasks=[consultation_task, inventory_task, delivery_task],\n",
        "        verbose=True,\n",
        "        process=Process.sequential,\n",
        "        planning_llm=llm\n",
        "    )\n",
        "\n",
        "    result = crew.kickoff()\n",
        "    print(f\"ü§ñ Complex order processing:\\n{result}\")\n",
        "    return result\n",
        "\n",
        "# =============================================================================\n",
        "# INTERACTIVE MENU FOR COLAB\n",
        "# =============================================================================\n",
        "\n",
        "def run_interactive_demo():\n",
        "    \"\"\"Interactive agent demonstration\"\"\"\n",
        "    print(\"ü©± AI AGENTS FOR LINGERIE BRAND\")\n",
        "    print(\"=\" * 60)\n",
        "    print(\"Welcome to the AI agents demonstration!\")\n",
        "    print(\"\\nAvailable scenarios:\")\n",
        "    print(\"1. üë©‚Äçüíº Customer consultation\")\n",
        "    print(\"2. üì¶ Product inventory check\")\n",
        "    print(\"3. üöö Delivery planning\")\n",
        "    print(\"4. üì¢ Marketing campaign creation\")\n",
        "    print(\"5. üõçÔ∏è Complex order processing\")\n",
        "    print(\"6. üß™ Run all tests\")\n",
        "\n",
        "    return True\n",
        "\n",
        "# =============================================================================\n",
        "# PRESET TESTS\n",
        "# =============================================================================\n",
        "\n",
        "def run_all_tests():\n",
        "    \"\"\"Run all test scenarios\"\"\"\n",
        "    print(\"üß™ RUNNING ALL TEST SCENARIOS\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Test 1: Consultation\n",
        "    scenario_customer_consultation(\n",
        "        \"Hello! I'm looking for a comfortable wireless bra for everyday wear, size 75B, preferably in dark colors\"\n",
        "    )\n",
        "\n",
        "    # Test 2: Inventory\n",
        "    scenario_inventory_check(\"Comfort Plus black 75B\")\n",
        "\n",
        "    # Test 3: Delivery\n",
        "    scenario_delivery_planning(\"Stefan cel Mare 126 street, Chisinau\")\n",
        "\n",
        "    # Test 4: Marketing\n",
        "    scenario_marketing_campaign(\n",
        "        \"Spring promotion: 25% discount on entire sports collection, target audience - active women 25-40 years old\"\n",
        "    )\n",
        "\n",
        "    # Test 5: Complex\n",
        "    scenario_complex_order()\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"‚úÖ ALL TESTS COMPLETED!\")\n",
        "    print(\"üöÄ Agents are ready to work!\")\n",
        "\n",
        "# =============================================================================\n",
        "# QUICK TESTS FOR INDIVIDUAL AGENTS\n",
        "# =============================================================================\n",
        "\n",
        "def quick_test_consultant():\n",
        "    \"\"\"Quick consultant test\"\"\"\n",
        "    print(\"‚ö° QUICK CONSULTANT TEST\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    result = scenario_customer_consultation(\n",
        "        \"Hello! What bra size would fit me if my underbust measurement is 75 cm?\"\n",
        "    )\n",
        "    return result\n",
        "\n",
        "def quick_test_warehouse():\n",
        "    \"\"\"Quick warehouse test\"\"\"\n",
        "    print(\"‚ö° QUICK WAREHOUSE TEST\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    result = scenario_inventory_check(\"black bra size 75B\")\n",
        "    return result\n",
        "\n",
        "def quick_test_logistics():\n",
        "    \"\"\"Quick logistics test\"\"\"\n",
        "    print(\"‚ö° QUICK LOGISTICS TEST\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    result = scenario_delivery_planning(\"Dacia 47 street, Botanica district\")\n",
        "    return result\n",
        "\n",
        "def quick_test_marketing():\n",
        "    \"\"\"Quick marketing test\"\"\"\n",
        "    print(\"‚ö° QUICK MARKETING TEST\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    result = scenario_marketing_campaign(\n",
        "        \"Valentine's Day campaign: 20% discount on romantic lingerie sets\"\n",
        "    )\n",
        "    return result\n",
        "\n",
        "# =============================================================================\n",
        "# SYSTEM STATUS CHECK\n",
        "# =============================================================================\n",
        "\n",
        "def system_check():\n",
        "    \"\"\"Check system status\"\"\"\n",
        "    print(\"üîç SYSTEM STATUS CHECK\")\n",
        "    print(\"=\" * 40)\n",
        "\n",
        "    print(f\"‚úÖ LLM model: {llm.model}\")\n",
        "    print(f\"‚úÖ Base URL: {llm.base_url}\")\n",
        "\n",
        "    print(f\"üì¶ Products in database: {len(PRODUCTS_DB)}\")\n",
        "    print(f\"üè™ Inventory records: {len(INVENTORY_DB)}\")\n",
        "    print(f\"üó∫Ô∏è Delivery zones: {len(DELIVERY_ZONES)}\")\n",
        "\n",
        "    print(\"\\nüìã Available products:\")\n",
        "    for pid, product in PRODUCTS_DB.items():\n",
        "        print(f\"  - {product['model']} {product['color']} {product['size']} (${product['price']})\")\n",
        "\n",
        "    print(\"\\nüè¨ Stores:\")\n",
        "    stores = set()\n",
        "    for inv in INVENTORY_DB.values():\n",
        "        stores.add(f\"{inv['store']} ({inv['address']})\")\n",
        "    for store in stores:\n",
        "        print(f\"  - {store}\")\n",
        "\n",
        "# Initialization completed\n",
        "print(\"‚úÖ Agents successfully initialized!\")\n",
        "print(\"üìö To run, use these functions:\")\n",
        "print(\"   - run_interactive_demo() - interactive menu\")\n",
        "print(\"   - run_all_tests() - run all tests\")\n",
        "print(\"   - quick_test_consultant() - test consultant\")\n",
        "print(\"   - quick_test_warehouse() - test warehouse manager\")\n",
        "print(\"   - quick_test_logistics() - test logistics\")\n",
        "print(\"   - quick_test_marketing() - test marketing\")\n",
        "print(\"   - system_check() - check system status\")"
      ],
      "metadata": {
        "id": "xt2xEZQYI8WR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================================================================\n",
        "# INTERACTIVE CUSTOMER CONSULTANT TESTER\n",
        "# =========================================================================\n",
        "\n",
        "import time\n",
        "from datetime import datetime\n",
        "\n",
        "print(\"ü§ñ INTERACTIVE CUSTOMER CONSULTANT TESTER\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =========================================================================\n",
        "# SIMPLE INTERACTIVE MODE\n",
        "# =========================================================================\n",
        "\n",
        "def chat_with_consultant():\n",
        "    \"\"\"Simple chat interface with the consultant\"\"\"\n",
        "    print(\"\\nüí¨ CHAT WITH CUSTOMER CONSULTANT\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Type your questions and get instant responses!\")\n",
        "    print(\"Type 'quit', 'exit', or 'stop' to end the session\")\n",
        "    print(\"Type 'help' for example questions\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    conversation_count = 0\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            # Get user input\n",
        "            user_question = input(\"\\nüë§ Your question: \").strip()\n",
        "\n",
        "            # Check for exit commands\n",
        "            if user_question.lower() in ['quit', 'exit', 'stop', 'bye']:\n",
        "                print(\"üëã Thank you for testing the consultant! Goodbye!\")\n",
        "                break\n",
        "\n",
        "            # Check for empty input\n",
        "            if not user_question:\n",
        "                print(\"‚ö†Ô∏è Please enter a question or type 'quit' to exit\")\n",
        "                continue\n",
        "\n",
        "            # Help command\n",
        "            if user_question.lower() == 'help':\n",
        "                show_example_questions()\n",
        "                continue\n",
        "\n",
        "            # Process the question\n",
        "            conversation_count += 1\n",
        "            print(f\"\\nü§ñ Consultant (Response #{conversation_count}):\")\n",
        "            print(\"-\" * 30)\n",
        "\n",
        "            start_time = time.time()\n",
        "            response = scenario_customer_consultation(user_question)\n",
        "            end_time = time.time()\n",
        "\n",
        "            print(f\"\\n‚è±Ô∏è Response time: {end_time - start_time:.2f} seconds\")\n",
        "            print(\"=\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã Session ended by user. Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "            print(\"Please try again or type 'quit' to exit\")\n",
        "\n",
        "# =========================================================================\n",
        "# GUIDED INTERACTIVE MODE\n",
        "# =========================================================================\n",
        "\n",
        "def guided_consultant_test():\n",
        "    \"\"\"Guided testing with categories\"\"\"\n",
        "    print(\"\\nüéØ GUIDED CONSULTANT TESTING\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    categories = {\n",
        "        \"1\": \"Bra Sizing Questions\",\n",
        "        \"2\": \"Style and Fit Questions\",\n",
        "        \"3\": \"Problem Solving\",\n",
        "        \"4\": \"Special Needs\",\n",
        "        \"5\": \"Product Recommendations\",\n",
        "        \"6\": \"Care and Maintenance\",\n",
        "        \"7\": \"Free Form Question\"\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nüìã Choose a category to test:\")\n",
        "        for key, value in categories.items():\n",
        "            print(f\"   {key}. {value}\")\n",
        "        print(\"   0. Exit\")\n",
        "\n",
        "        try:\n",
        "            choice = input(\"\\nEnter category number (0-7): \").strip()\n",
        "\n",
        "            if choice == \"0\":\n",
        "                print(\"üëã Goodbye!\")\n",
        "                break\n",
        "            elif choice in categories:\n",
        "                if choice == \"7\":\n",
        "                    # Free form\n",
        "                    question = input(\"\\nüë§ Enter your question: \").strip()\n",
        "                else:\n",
        "                    # Guided question for category\n",
        "                    question = get_guided_question(choice)\n",
        "\n",
        "                if question:\n",
        "                    print(f\"\\nü§ñ Testing: {question}\")\n",
        "                    print(\"-\" * 50)\n",
        "                    start_time = time.time()\n",
        "                    response = scenario_customer_consultation(question)\n",
        "                    end_time = time.time()\n",
        "                    print(f\"\\n‚è±Ô∏è Response time: {end_time - start_time:.2f} seconds\")\n",
        "\n",
        "                    # Ask for rating\n",
        "                    rate_response()\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Invalid choice. Please enter 0-7\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã Session ended. Goodbye!\")\n",
        "            break\n",
        "\n",
        "# =========================================================================\n",
        "# QUESTION HELPERS\n",
        "# =========================================================================\n",
        "\n",
        "def show_example_questions():\n",
        "    \"\"\"Show example questions for inspiration\"\"\"\n",
        "    print(\"\\nüí° EXAMPLE QUESTIONS:\")\n",
        "    print(\"-\" * 30)\n",
        "\n",
        "    examples = {\n",
        "        \"Sizing\": [\n",
        "            \"What size should I wear if my underbust is 75cm?\",\n",
        "            \"I usually wear 34B but it feels tight. What should I try?\",\n",
        "            \"How do I convert US size 34C to European sizing?\"\n",
        "        ],\n",
        "        \"Style\": [\n",
        "            \"What bra works best under a tight white t-shirt?\",\n",
        "            \"I need a strapless bra for my wedding dress\",\n",
        "            \"What's the most supportive sports bra for running?\"\n",
        "        ],\n",
        "        \"Problems\": [\n",
        "            \"My bra straps keep falling down. How do I fix this?\",\n",
        "            \"I get red marks from my underwire. What's wrong?\",\n",
        "            \"The center gore doesn't lie flat against my chest\"\n",
        "        ],\n",
        "        \"Special\": [\n",
        "            \"I'm pregnant and my size keeps changing. Help!\",\n",
        "            \"I need comfortable nursing bras\",\n",
        "            \"What's good for a teenager's first bra?\"\n",
        "        ]\n",
        "    }\n",
        "\n",
        "    for category, questions in examples.items():\n",
        "        print(f\"\\nüè∑Ô∏è {category}:\")\n",
        "        for q in questions:\n",
        "            print(f\"   ‚Ä¢ {q}\")\n",
        "\n",
        "def get_guided_question(category_num):\n",
        "    \"\"\"Get guided question based on category\"\"\"\n",
        "    prompts = {\n",
        "        \"1\": \"Enter a bra sizing question (measurements, fit issues, size conversions): \",\n",
        "        \"2\": \"Enter a style question (what bra for what outfit/occasion): \",\n",
        "        \"3\": \"Describe a bra fitting problem you're experiencing: \",\n",
        "        \"4\": \"Ask about special needs (pregnancy, nursing, medical, etc.): \",\n",
        "        \"5\": \"Ask for product recommendations (brands, types, budget): \",\n",
        "        \"6\": \"Ask about bra care and maintenance: \"\n",
        "    }\n",
        "\n",
        "    prompt = prompts.get(category_num, \"Enter your question: \")\n",
        "    return input(f\"\\nüë§ {prompt}\").strip()\n",
        "\n",
        "def rate_response():\n",
        "    \"\"\"Allow user to rate the response\"\"\"\n",
        "    try:\n",
        "        print(\"\\n‚≠ê How would you rate this response?\")\n",
        "        print(\"1 = Poor, 2 = Fair, 3 = Good, 4 = Very Good, 5 = Excellent\")\n",
        "        rating = input(\"Rating (1-5) or press Enter to skip: \").strip()\n",
        "\n",
        "        if rating in ['1', '2', '3', '4', '5']:\n",
        "            rating_text = ['Poor', 'Fair', 'Good', 'Very Good', 'Excellent'][int(rating)-1]\n",
        "            print(f\"‚úÖ Thank you! You rated this response: {rating}/5 ({rating_text})\")\n",
        "\n",
        "            if int(rating) <= 2:\n",
        "                feedback = input(\"üí¨ What could be improved? (optional): \").strip()\n",
        "                if feedback:\n",
        "                    print(f\"üìù Feedback noted: {feedback}\")\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "# =========================================================================\n",
        "# BATCH TESTING MODE\n",
        "# =========================================================================\n",
        "\n",
        "def batch_test_mode():\n",
        "    \"\"\"Test multiple questions in batch\"\"\"\n",
        "    print(\"\\nüìä BATCH TESTING MODE\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Enter multiple questions (one per line)\")\n",
        "    print(\"Type 'END' on a new line when finished\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    questions = []\n",
        "\n",
        "    while True:\n",
        "        question = input(\"Question: \").strip()\n",
        "        if question.upper() == 'END':\n",
        "            break\n",
        "        if question:\n",
        "            questions.append(question)\n",
        "\n",
        "    if not questions:\n",
        "        print(\"‚ö†Ô∏è No questions entered\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüöÄ Testing {len(questions)} questions...\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    total_time = 0\n",
        "\n",
        "    for i, question in enumerate(questions, 1):\n",
        "        print(f\"\\nüìù Question {i}/{len(questions)}: {question}\")\n",
        "        print(\"-\" * 40)\n",
        "\n",
        "        start_time = time.time()\n",
        "        response = scenario_customer_consultation(question)\n",
        "        end_time = time.time()\n",
        "\n",
        "        response_time = end_time - start_time\n",
        "        total_time += response_time\n",
        "\n",
        "        print(f\"‚è±Ô∏è Time: {response_time:.2f}s\")\n",
        "        print(\"=\" * 50)\n",
        "\n",
        "    print(f\"\\nüìà BATCH RESULTS:\")\n",
        "    print(f\"   Total questions: {len(questions)}\")\n",
        "    print(f\"   Total time: {total_time:.2f}s\")\n",
        "    print(f\"   Average time: {total_time/len(questions):.2f}s per question\")\n",
        "\n",
        "# =========================================================================\n",
        "# CONVERSATION MODE\n",
        "# =========================================================================\n",
        "\n",
        "def conversation_mode():\n",
        "    \"\"\"Extended conversation with context\"\"\"\n",
        "    print(\"\\nüí≠ CONVERSATION MODE\")\n",
        "    print(\"-\" * 40)\n",
        "    print(\"Have an extended conversation with the consultant\")\n",
        "    print(\"The agent will remember the context of your conversation\")\n",
        "    print(\"Type 'quit' to end the conversation\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "    conversation_history = []\n",
        "\n",
        "    while True:\n",
        "        try:\n",
        "            question = input(f\"\\nüë§ You (message #{len(conversation_history)+1}): \").strip()\n",
        "\n",
        "            if question.lower() in ['quit', 'exit', 'stop']:\n",
        "                break\n",
        "\n",
        "            if not question:\n",
        "                continue\n",
        "\n",
        "            # Add context from previous conversation\n",
        "            if conversation_history:\n",
        "                context_question = f\"Previous context: {' '.join(conversation_history[-3:])} Current question: {question}\"\n",
        "            else:\n",
        "                context_question = question\n",
        "\n",
        "            print(f\"\\nü§ñ Consultant:\")\n",
        "            print(\"-\" * 20)\n",
        "\n",
        "            start_time = time.time()\n",
        "            response = scenario_customer_consultation(context_question)\n",
        "            end_time = time.time()\n",
        "\n",
        "            conversation_history.append(f\"Q: {question}\")\n",
        "            conversation_history.append(f\"A: {str(response)[:100]}\")\n",
        "\n",
        "            print(f\"\\n‚è±Ô∏è Response time: {end_time - start_time:.2f}s\")\n",
        "            print(f\"üí¨ Conversation length: {len(conversation_history)//2} exchanges\")\n",
        "            print(\"-\" * 50)\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            break\n",
        "\n",
        "    print(f\"\\nüìä Conversation ended. Total exchanges: {len(conversation_history)//2}\")\n",
        "\n",
        "# =========================================================================\n",
        "# MAIN INTERACTIVE MENU\n",
        "# =========================================================================\n",
        "\n",
        "def interactive_menu():\n",
        "    \"\"\"Main interactive menu\"\"\"\n",
        "    print(\"\\nüéÆ INTERACTIVE CONSULTANT TESTER\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    modes = {\n",
        "        \"1\": (\"Simple Chat\", chat_with_consultant),\n",
        "        \"2\": (\"Guided Testing\", guided_consultant_test),\n",
        "        \"3\": (\"Batch Testing\", batch_test_mode),\n",
        "        \"4\": (\"Conversation Mode\", conversation_mode),\n",
        "        \"5\": (\"Show Examples\", show_example_questions)\n",
        "    }\n",
        "\n",
        "    while True:\n",
        "        print(\"\\nüìã Choose testing mode:\")\n",
        "        for key, (name, _) in modes.items():\n",
        "            print(f\"   {key}. {name}\")\n",
        "        print(\"   0. Exit\")\n",
        "\n",
        "        try:\n",
        "            choice = input(\"\\nEnter mode number (0-5): \").strip()\n",
        "\n",
        "            if choice == \"0\":\n",
        "                print(\"üëã Thank you for testing! Goodbye!\")\n",
        "                break\n",
        "            elif choice in modes:\n",
        "                mode_name, mode_function = modes[choice]\n",
        "                print(f\"\\nüöÄ Starting {mode_name}...\")\n",
        "                mode_function()\n",
        "            else:\n",
        "                print(\"‚ö†Ô∏è Invalid choice. Please enter 0-5\")\n",
        "\n",
        "        except KeyboardInterrupt:\n",
        "            print(\"\\n\\nüëã Goodbye!\")\n",
        "            break\n",
        "        except Exception as e:\n",
        "            print(f\"\\n‚ùå Error: {e}\")\n",
        "\n",
        "# =========================================================================\n",
        "# QUICK START FUNCTIONS\n",
        "# =========================================================================\n",
        "\n",
        "def start_chat():\n",
        "    \"\"\"Quick start for simple chat\"\"\"\n",
        "    chat_with_consultant()\n",
        "\n",
        "def start_guided():\n",
        "    \"\"\"Quick start for guided testing\"\"\"\n",
        "    guided_consultant_test()\n",
        "\n",
        "def start_interactive():\n",
        "    \"\"\"Quick start for full interactive menu\"\"\"\n",
        "    interactive_menu()\n",
        "\n",
        "# =========================================================================\n",
        "# USAGE INSTRUCTIONS\n",
        "# =========================================================================\n",
        "\n",
        "print(\"\"\"\n",
        "üéØ INTERACTIVE TESTING OPTIONS:\n",
        "\n",
        "üöÄ QUICK START:\n",
        "- start_chat() - Simple question-answer chat\n",
        "- start_guided() - Category-based guided testing\n",
        "- start_interactive() - Full interactive menu\n",
        "\n",
        "üí¨ TESTING MODES:\n",
        "1. Simple Chat - Ask any question, get instant answers\n",
        "2. Guided Testing - Choose categories, get prompts\n",
        "3. Batch Testing - Test multiple questions at once\n",
        "4. Conversation Mode - Extended dialogues with context\n",
        "5. Examples - See sample questions for inspiration\n",
        "\n",
        "‚å®Ô∏è COMMANDS IN CHAT:\n",
        "- Type your question normally\n",
        "- 'help' - Show example questions\n",
        "- 'quit'/'exit'/'stop' - End session\n",
        "- Ctrl+C - Emergency exit\n",
        "\n",
        "üí° TIPS:\n",
        "- Start with start_chat() for immediate testing\n",
        "- Use guided mode to explore different question types\n",
        "- Batch mode is great for systematic testing\n",
        "- Conversation mode tests context awareness\n",
        "\n",
        "üéÆ Ready to start interactive testing!\n",
        "Type: start_chat() to begin\n",
        "\"\"\")"
      ],
      "metadata": {
        "id": "nSWS8nc1tWvi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start_chat()"
      ],
      "metadata": {
        "id": "Uy6yv9CsvjwO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import subprocess\n",
        "import threading\n",
        "import time\n",
        "import requests\n",
        "\n",
        "print(\"üîç –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç–∞—Ç—É—Å Ollama —Å–µ—Ä–≤–µ—Ä–∞...\")\n",
        "\n",
        "# –ü—Ä–æ–≤–µ—Ä—è–µ–º, —Ä–∞–±–æ—Ç–∞–µ—Ç –ª–∏ —Å–µ—Ä–≤–µ—Ä\n",
        "try:\n",
        "    response = requests.get(\"http://127.0.0.1:11434\", timeout=5)\n",
        "    print(\"‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä —É–∂–µ –∑–∞–ø—É—â–µ–Ω!\")\n",
        "except:\n",
        "    print(\"‚ùå Ollama —Å–µ—Ä–≤–µ—Ä –Ω–µ –æ—Ç–≤–µ—á–∞–µ—Ç. –ó–∞–ø—É—Å–∫–∞–µ–º...\")\n",
        "\n",
        "    # –ó–∞–ø—É—Å–∫–∞–µ–º —Å–µ—Ä–≤–µ—Ä –≤ —Ñ–æ–Ω–æ–≤–æ–º —Ä–µ–∂–∏–º–µ\n",
        "    def run_ollama():\n",
        "        subprocess.Popen([\"ollama\", \"serve\"])\n",
        "\n",
        "    thread = threading.Thread(target=run_ollama)\n",
        "    thread.daemon = True  # –î–µ–º–æ–Ω –ø–æ—Ç–æ–∫\n",
        "    thread.start()\n",
        "\n",
        "    print(\"‚è≥ –ñ–¥–µ–º –∑–∞–ø—É—Å–∫–∞ —Å–µ—Ä–≤–µ—Ä–∞...\")\n",
        "    time.sleep(10)  # –î–∞–µ–º –≤—Ä–µ–º—è –Ω–∞ –∑–∞–ø—É—Å–∫\n",
        "\n",
        "    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–Ω–æ–≤–∞\n",
        "    try:\n",
        "        response = requests.get(\"http://127.0.0.1:11434\", timeout=10)\n",
        "        print(\"‚úÖ Ollama —Å–µ—Ä–≤–µ—Ä —É—Å–ø–µ—à–Ω–æ –∑–∞–ø—É—â–µ–Ω!\")\n",
        "    except:\n",
        "        print(\"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø—É—Å—Ç–∏—Ç—å —Å–µ—Ä–≤–µ—Ä. –ü–æ–ø—Ä–æ–±—É–µ–º –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–Ω—ã–π —Å–ø–æ—Å–æ–±...\")\n"
      ],
      "metadata": {
        "id": "4jbxAhm9l2Sf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}